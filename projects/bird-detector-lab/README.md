# ğŸ¦ Bird Detector Lab  
**Exploring practical approaches to bird detection in real-world ecological data, including what works, what breaks, and why.**

This project is my practical sandbox for applying machine learning to bird detection in aerial and nonâ€‘aerial imagery, inspired by ecological ML research.  
It is **not** just a â€œlook, it runsâ€ demo â€” it is a record of **attempts, dead ends, and working paths** when trying to do bird detection with imperfect, evolving tools.

The goal is to think and work like a researcher:
- try plausible approaches,
- see where they fail in practice,
- document those failures clearly,
- and then design better, more realistic pipelines.

---

## ğŸ“˜ What This Project Currently Contains (and Learns From)

### 1. DeepForest + BirdDetector Attempt (Drone Imagery)

**Status:** âŒ Abandoned as a primary path, kept for lessons learned.

- Tried to use DeepForest + BirdDetector for drone bird detection, following older papers and repos.
- Ran into:
  - severe version conflicts (Python, torch, albumentations),
  - outdated APIs (`use_bird_detector`, `load_model`),
  - missing or shifting model weights,
  - confusing, hardâ€‘coded labels (`Tree`) despite loading bird weights.
- **Key takeaway:** older academic code can be extremely brittle; reproducing results often requires pinning old environments and manually loading weights. This is valuable to know, but not a good foundation for a modern portfolio project.

Iâ€™m keeping notes and minimal code from this attempt as a **â€œwhat went wrong and whyâ€** case study.

---

### 2. Hugging Face Bird Models (Nonâ€‘Drone, Speciesâ€‘Level)

**Status:** âš ï¸ Informative but not directly suitable for drone imagery.

- Explored using models like `weecology/everglades-bird-species-detector` from Hugging Face.
- These models:
  - are trained mostly on groundâ€‘level or nonâ€‘orthomosaic imagery,
  - do provide species labels and clean APIs,
  - but donâ€™t straightforwardly transfer to highâ€‘altitude drone imagery where birds are tiny.
- **Key takeaway:** even when a model is â€œfor birdsâ€ and â€œfor detectionâ€, domain shift (viewpoint, scale, background, resolution) makes direct reuse nonâ€‘trivial.

These experiments helped sharpen my understanding of **domain shift** and why â€œjust grab a HF modelâ€ is rarely enough in ecology.

---

## ğŸ§ª What This Lab Is Moving Toward

Instead of pretending there is a single perfect plugâ€‘andâ€‘play model for drone birds (there isnâ€™t), this lab is evolving toward:

- **Realistic pipelines** that combine:
  - a general wildlife detector (e.g., MegaDetector or YOLOâ€‘based models),
  - SAHI or tiling for small objects,
  - optional species classifiers on cropped detections.
- **Transparent documentation** of:
  - which models were tried,
  - under what conditions they break,
  - and what I would do next to make them work in practice.
- **Reproducible notebooks** where:
  - environment assumptions are explicit,
  - limitations are acknowledged instead of hidden.

Future notebooks will likely be renamed and reorganized around this idea:
- `01_exploratory_detection.ipynb` â€“ trying different detectors on a small set of images.
- `02_sahi_and_tiling.ipynb` â€“ inspecting how slicing affects small bird detection.
- `03_realistic_pipeline.ipynb` â€“ combining a working detector + postâ€‘processing.

---

## ğŸ“ Folder Breakdown (Conceptual)

- `notebooks/` â€” experiments and exploratory analysis (including failed/abandoned paths, clearly marked).  
- `models/` â€” wrappers around whatever detector(s) I end up using (e.g., HF models, YOLO, MegaDetector).  
- `utils/` â€” tiling, visualization, metrics helpers.  
- `data/` â€” local data (ignored from git).  
- `results/` â€” saved visualizations, logs, and comparison outputs.

---

## ğŸ§  Higherâ€‘Level Goals

- Understand **why** drone bird detection is hard (tiny objects, noisy labels, habitat shift).
- Experience firstâ€‘hand the **friction of working with academic ML code**.
- Build a habit of documenting:
  - what I tried,
  - what broke,
  - what I learned,
  - and how Iâ€™d design a better next iteration.
- Slowly converge on a **robust, modern, reproducible birdâ€‘detection pipeline** that Iâ€™d be comfortable showing to a conservationâ€‘tech employer.

---

## ğŸ“„ License  

MIT License